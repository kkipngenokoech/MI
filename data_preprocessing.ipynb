{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVkihH4W7Cdon7Z05VL1G/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkipngenokoech/MI/blob/main/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the data"
      ],
      "metadata": {
        "id": "jzZYzVx0t4QW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q9r4ZXm_c3RC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee9cc2e4-333f-4643-b785-4b859fccbe50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-16 04:02:25--  https://media.githubusercontent.com/media/kkipngenokoech/MI/refs/heads/main/smrdata.zip\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1540873695 (1.4G) [application/zip]\n",
            "Saving to: ‘smrdata.zip’\n",
            "\n",
            "smrdata.zip         100%[===================>]   1.43G  82.4MB/s    in 19s     \n",
            "\n",
            "2025-11-16 04:02:44 (78.9 MB/s) - ‘smrdata.zip’ saved [1540873695/1540873695]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://media.githubusercontent.com/media/kkipngenokoech/MI/refs/heads/main/smrdata.zip -O smrdata.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip smrdata.zip > /dev/null 2>&1\n",
        "%cd smrdata\n"
      ],
      "metadata": {
        "id": "iV3lwU6ppyZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPORTS"
      ],
      "metadata": {
        "id": "4c176t-Jt8OT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "metadata": {
        "id": "cIwZIwIYt-cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# ---- CONFIG ----\n",
        "data_dir = \"Session1\"        # folder containing the .mat file\n",
        "vis_seconds = 3              # how many seconds of data to plot\n",
        "downsample = 4               # plot every Nth sample\n",
        "offset = 400                 # vertical shift between channels (μV)\n",
        "# -----------------\n",
        "\n",
        "# pick the first .mat file automatically\n",
        "files = sorted([f for f in os.listdir(data_dir) if f.endswith(\".mat\")])\n",
        "if not files:\n",
        "    raise RuntimeError(\"No .mat files found.\")\n",
        "matfile = os.path.join(data_dir, files[0])\n",
        "\n",
        "# load\n",
        "run = sio.loadmat(matfile)[\"runData\"][0, 0]\n",
        "\n",
        "fs = int(run[\"fs\"][0, 0])             # sampling rate\n",
        "X = run[\"allData\"]                   # (channels, samples)\n",
        "\n",
        "# fix labels\n",
        "labels_array = run[\"label\"]\n",
        "labels = [str(l[0]) if isinstance(l, np.ndarray) else str(l) for l in labels_array.flatten()]\n",
        "\n",
        "nch, nsamp = X.shape\n",
        "assert len(labels) == nch, f\"Number of labels ({len(labels)}) does not match number of channels ({nch})\"\n",
        "\n",
        "ts = run[\"trialStart\"].flatten().astype(int)\n",
        "\n",
        "# ---- determine range first ----\n",
        "N = min(int(vis_seconds * fs), nsamp)\n",
        "t = np.arange(N)[::downsample] / fs\n",
        "\n",
        "# ---- select only active electrodes ----\n",
        "active_labels = [\n",
        "    'F3','F4','Fc5','Fc3','Fc1','Fcz','Fc2','Fc4','Fc6',\n",
        "    'T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n",
        "    'Cp5','Cp3','Cp1','Cpz','Cp2','Cp4','Cp6','P3','P4'\n",
        "]\n",
        "active_idx = [i for i, l in enumerate(labels) if l in active_labels]\n",
        "\n",
        "# subset data\n",
        "Y = X[active_idx, :N][:, ::downsample]\n",
        "labels = [labels[i] for i in active_idx]\n",
        "nch = len(active_idx)\n",
        "\n",
        "print(\"File:\", matfile)\n",
        "print(\"Channels (active only):\", nch, \"Samples:\", nsamp, \"fs:\", fs)\n",
        "\n",
        "# ---- plot normalized, vertically shifted signals ----\n",
        "plt.figure(figsize=(14, 8))\n",
        "for i in range(nch):\n",
        "    y = Y[i]\n",
        "    y_norm = (y - np.mean(y)) / np.std(y)  # z-score\n",
        "    plt.plot(t, y_norm + i, linewidth=0.5)  # vertical shift by index\n",
        "\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Channels\")\n",
        "plt.yticks(range(nch), labels if nch <= 80 else [])\n",
        "plt.title(f\"{files[0]} | normalized channels | first {vis_seconds}s\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gJE6_gAwp8ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA PRE-PROCESSING"
      ],
      "metadata": {
        "id": "QyG20EYbtlR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne"
      ],
      "metadata": {
        "id": "3sYwi5kNvxB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, filtfilt\n",
        "import os\n",
        "\n",
        "# ---- CONFIG ----\n",
        "data_dir = \"Session1\"\n",
        "downsample = 4\n",
        "lowcut = 8\n",
        "highcut = 30\n",
        "baseline_window = (-2, 0)    # 2s pre-trialStart\n",
        "epoch_window = (-2, 2)       # 2s pre + 2s post trialStart\n",
        "\n",
        "# ---- LOAD DATA ----\n",
        "files = sorted([f for f in os.listdir(data_dir) if f.endswith(\".mat\")])\n",
        "matfile = os.path.join(data_dir, files[0])\n",
        "run = sio.loadmat(matfile)[\"runData\"][0, 0]\n",
        "\n",
        "fs = int(run[\"fs\"][0, 0])\n",
        "X = run[\"allData\"]\n",
        "labels_array = run[\"label\"]\n",
        "labels = [str(l[0]) if isinstance(l, np.ndarray) else str(l) for l in labels_array.flatten()]\n",
        "\n",
        "# ---- SELECT ACTIVE ELECTRODES ----\n",
        "active_labels = [\n",
        "    'F3','F4','Fc5','Fc3','Fc1','Fcz','Fc2','Fc4','Fc6',\n",
        "    'T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n",
        "    'Cp5','Cp3','Cp1','Cpz','Cp2','Cp4','Cp6','P3','P4'\n",
        "]\n",
        "active_idx = [i for i, l in enumerate(labels) if l in active_labels]\n",
        "X = X[active_idx, :]\n",
        "labels = [labels[i] for i in active_idx]\n",
        "nch = len(active_idx)\n",
        "\n",
        "# ---- BANDPASS FILTER ----\n",
        "def bandpass(data, low, high, fs, order=4):\n",
        "    b, a = butter(order, [low/(fs/2), high/(fs/2)], btype='band')\n",
        "    return filtfilt(b, a, data, axis=1)\n",
        "\n",
        "X_filt = bandpass(X, lowcut, highcut, fs)\n",
        "\n",
        "# ---- DOWNSAMPLE ----\n",
        "X_ds = X_filt[:, ::downsample]\n",
        "fs_new = fs / downsample\n",
        "\n",
        "# ---- COMMON AVERAGE REFERENCE ----\n",
        "X_car = X_ds - X_ds.mean(axis=0, keepdims=True)\n",
        "\n",
        "# ---- VALID TRIALS ----\n",
        "outcome = run[\"outcome\"].flatten()\n",
        "valid_idx = np.where(outcome != 0)[0]\n",
        "\n",
        "# ---- EPOCH EXTRACTION (pre-cue + post) ----\n",
        "ts = run[\"trialStart\"].flatten().astype(int)\n",
        "epoch_samples = int((epoch_window[1]-epoch_window[0])*fs_new)\n",
        "epochs = []\n",
        "y_labels = []\n",
        "for i, s in enumerate(ts):\n",
        "    if i not in valid_idx:\n",
        "        continue\n",
        "    start = int((s/fs + epoch_window[0])*fs_new)\n",
        "    end = start + epoch_samples\n",
        "    if start >= 0 and end <= X_car.shape[1]:\n",
        "        epochs.append(X_car[:, start:end])\n",
        "        y_labels.append(run[\"target\"].flatten()[i])\n",
        "epochs = np.stack(epochs, axis=0)\n",
        "y_labels = np.array(y_labels)\n",
        "y_dl = y_labels - 1  # convert 1/2 → 0/1 for deep learning\n",
        "\n",
        "# ---- BASELINE CORRECTION ----\n",
        "baseline_idx = (int((baseline_window[0]-epoch_window[0])*fs_new),\n",
        "                int((baseline_window[1]-epoch_window[0])*fs_new))\n",
        "epochs_baseline = epochs - epochs[:, :, baseline_idx[0]:baseline_idx[1]].mean(axis=2, keepdims=True)\n",
        "\n",
        "# ---- PLOT FIRST TRIAL ----\n",
        "plt.figure(figsize=(14,8))\n",
        "scale = 2.0\n",
        "for i in range(nch):\n",
        "    y = epochs_baseline[0, i, :]\n",
        "    plt.plot(y + i*scale, linewidth=0.5)\n",
        "plt.yticks([i*scale for i in range(nch)], labels)\n",
        "plt.xlabel(\"Samples\")\n",
        "plt.ylabel(\"Channels\")\n",
        "plt.title(\"First trial, CAR + filtered + baseline-corrected (pre-cue included)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Z-ne4Lkdv6ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FEATURE EXTRACTION"
      ],
      "metadata": {
        "id": "_kkFOuS4wqn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bandpower + LDA"
      ],
      "metadata": {
        "id": "N4yO9inpxXlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import welch\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "def bandpower_epochs(epochs, fs, bands=[(8,12),(13,30)]):\n",
        "    n_trials, n_channels, n_samples = epochs.shape\n",
        "    features = []\n",
        "    for tr in range(n_trials):\n",
        "        trial_features = []\n",
        "        for ch in range(n_channels):\n",
        "            f, Pxx = welch(epochs[tr,ch,:], fs=fs, nperseg=256)\n",
        "            for (low, high) in bands:\n",
        "                idx = np.logical_and(f >= low, f <= high)\n",
        "                trial_features.append(Pxx[idx].mean())\n",
        "        features.append(trial_features)\n",
        "    return np.array(features)\n",
        "\n",
        "X_features = bandpower_epochs(epochs_baseline, fs_new)\n",
        "y_labels = np.array(run['outcome'].flatten())  # assuming 0/1 for Left/Right MI\n",
        "clf = LDA()\n",
        "clf.fit(X_features, y_labels)\n"
      ],
      "metadata": {
        "id": "_ORCOWPfwMbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bandpower + SVM"
      ],
      "metadata": {
        "id": "QgQtkxLQxc7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "clf_svm = SVC(kernel='linear')\n",
        "clf_svm.fit(X_features, y_labels)\n"
      ],
      "metadata": {
        "id": "S49CdmizxghV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Common Spatial Patterns (CSP) + LDA"
      ],
      "metadata": {
        "id": "zTCgem_Fxjlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mne.decoding import CSP\n",
        "\n",
        "csp = CSP(n_components=4, reg=None)\n",
        "X_csp = csp.fit_transform(epochs_baseline, y_labels)\n",
        "clf_csp = LDA()\n",
        "clf_csp.fit(X_csp, y_labels)\n"
      ],
      "metadata": {
        "id": "gesHPRyvxmcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### deep learning"
      ],
      "metadata": {
        "id": "mV85E-2AxpyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Keras / TensorFlow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, GlobalAveragePooling1D, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(16, kernel_size=64, padding='same', input_shape=(nch, epoch_samples)),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Conv1D(32, kernel_size=32, padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(epochs_baseline, y_labels, epochs=50, batch_size=16, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "f29NA9icxv9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### general pipeline"
      ],
      "metadata": {
        "id": "NT9PmzNfxxfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.signal import welch\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from mne.decoding import CSP\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, GlobalAveragePooling1D, Dense, Dropout\n",
        "\n",
        "# --- Ensure y_labels matches valid trials (remove aborted trials) ---\n",
        "valid_idx = np.where(run[\"outcome\"].flatten() != 0)[0]\n",
        "y_labels = run[\"target\"].flatten()[valid_idx]  # original labels: 1/2\n",
        "epochs_baseline = epochs_baseline[valid_idx, :, :]\n",
        "n_trials, n_channels, n_samples = epochs_baseline.shape\n",
        "\n",
        "# --- 1) Bandpower Features ---\n",
        "def bandpower_epochs(epochs, fs, bands=[(8,12),(13,30)]):\n",
        "    features = []\n",
        "    for tr in range(epochs.shape[0]):\n",
        "        trial_features = []\n",
        "        for ch in range(epochs.shape[1]):\n",
        "            f, Pxx = welch(epochs[tr,ch,:], fs=fs, nperseg=256)\n",
        "            for (low, high) in bands:\n",
        "                idx = np.logical_and(f >= low, f <= high)\n",
        "                trial_features.append(Pxx[idx].mean())\n",
        "        features.append(trial_features)\n",
        "    return np.array(features)\n",
        "\n",
        "X_bp = bandpower_epochs(epochs_baseline, fs_new)\n",
        "\n",
        "# --- 1a) LDA ---\n",
        "lda = LDA()\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "score_lda = cross_val_score(lda, X_bp, y_labels, cv=cv)\n",
        "print(\"Bandpower + LDA PVC: %.2f%%\" % (score_lda.mean()*100))\n",
        "\n",
        "# --- 1b) SVM ---\n",
        "svm = SVC(kernel='linear')\n",
        "score_svm = cross_val_score(svm, X_bp, y_labels, cv=cv)\n",
        "print(\"Bandpower + SVM PVC: %.2f%%\" % (score_svm.mean()*100))\n",
        "\n",
        "# --- 2) CSP + LDA ---\n",
        "csp = CSP(n_components=4, reg=None)\n",
        "X_csp = csp.fit_transform(epochs_baseline, y_labels)\n",
        "lda_csp = LDA()\n",
        "score_csp = cross_val_score(lda_csp, X_csp, y_labels, cv=cv)\n",
        "print(\"CSP + LDA PVC: %.2f%%\" % (score_csp.mean()*100))\n",
        "\n",
        "# --- Prepare labels for deep learning (0/1) ---\n",
        "y_dl = y_labels - 1  # convert 1/2 → 0/1\n",
        "X_cnn = epochs_baseline.transpose(0,2,1)  # shape: (n_trials, n_samples, n_channels)\n",
        "\n",
        "# --- 3) 1D CNN ---\n",
        "cnn_model = Sequential([\n",
        "    Conv1D(16, kernel_size=64, padding='same', input_shape=(n_samples, n_channels)),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Conv1D(32, kernel_size=32, padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_model.fit(X_cnn, y_dl, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
        "\n",
        "cnn_score = cnn_model.evaluate(X_cnn, y_dl, verbose=0)\n",
        "print(\"1D CNN PVC: %.2f%%\" % (cnn_score[1]*100))\n",
        "\n",
        "# --- 4) EEGNet-like model ---\n",
        "def EEGNet(input_shape, n_classes=2):\n",
        "    model = Sequential([\n",
        "        Conv1D(16, kernel_size=64, padding='same', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        Activation('relu'),\n",
        "        Conv1D(32, kernel_size=32, padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Activation('relu'),\n",
        "        GlobalAveragePooling1D(),\n",
        "        Dropout(0.5),\n",
        "        Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "eegnet = EEGNet((n_samples, n_channels))\n",
        "eegnet.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "eegnet.fit(X_cnn, y_dl, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
        "eegnet_score = eegnet.evaluate(X_cnn, y_dl, verbose=0)\n",
        "print(\"EEGNet PVC: %.2f%%\" % (eegnet_score[1]*100))\n"
      ],
      "metadata": {
        "id": "Cg460JRdx6mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T4WlFvB20emX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}